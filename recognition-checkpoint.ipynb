{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "data = pd.read_csv('TestData.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlever les colonnes U0.......U20\n",
    "data=data.iloc[0:,19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifier si les données sont valide\n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permet de rapprocher les valeurs un peu près comme normalisation\n",
    "#label_Classe= LabelEncoder() \n",
    "#data['Classe']=label_Classe.fit_transform(data['Classe'])#utile pour normaliser les valeurs des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permet de compter le nombre de répetition de chaque classe\n",
    "data['Classe'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Classe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =data.drop('Classe',axis=1)  # dans x on garde toutes les colonnes sauf la classe\n",
    "Y =data['Classe'] # dans y on garde la classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on divisie notre dataSet en 2 parties une pour l'entrainement et une pour le test\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test\n",
    "Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Random Forest Classifier\n",
    "# Définition : est une technique d'apprentissage automatique, elle se base sur une forêt d'arbre de décision\n",
    "# chaque arbre de décision fournit ça propre décision , ainsi un vote est fait et la décision qu'à le plus de vote est élu comme décision final de l'arbre.\n",
    "\n",
    "# ### Avantages\n",
    "# - ils sont utilsé dans la classification et la régression\n",
    "# - gére et maintient la précision pour les données manquants\n",
    "# - quand le nombre d'arbres est plus grand que le nombres de donnée  dans le dataSet il est garanti  qu'il n y aura pas de sur-apprentissage a cause du system de bagging et sous-espaces aléatoires \n",
    "# - gére des grand dataset avec de grandes dimension\n",
    "\n",
    "# ### Inconvénients\n",
    "# - malgré qu'ils sont utile pour la classification , ils le sont moins que pour la régression du faite qu'il nous donne pas des valeurs pour savoir a quel pourcentage un element est de classe A ou B , en effet il répond il est de classe A ou de classe B , mais on ne sais pas a quel point.\n",
    "# - on a pas de controle sur ce que fait le modèle\n",
    "\n",
    "# ### Application\n",
    "# - le secteur des banques , dans l'évaluation des risque\n",
    "# - les gains/pertes dans le domaine de la bourse\n",
    "# - ....\n",
    "\n",
    "# ### mots clés \n",
    "\n",
    "# - Bagging : est un meta algorithm d'ensemble , qui augmente la stabilité et réduit la variance, les données sont piochées aléatoirement et mis dans des sous ensemble, a chaque entrainement le modèle utilise un sous ensemble totalement différent pour éviter le sur-apprentissage \n",
    "\n",
    "# ## Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ici on a choisi juste 3 arbres étant donné que la taille de notre data set n'est pas grande\n",
    "rfc = RandomForestClassifier(n_estimators=4) \n",
    "rfc.fit(X_train,Y_train)\n",
    "pred_rfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_rfc)\n",
    "# # analyse du rapport de la classification :\n",
    "#      - on peut voir la précision du model, après avoir été entrainé sur notre DataSet\n",
    "#      - on peut aussi voir la précision de classification de chaque classe comparé aux autres par exemple les classe de 3 a 9 sont a 100% détéctées contrairement 0 1 et 2 que le modèle les confends avec un taux pas très élever .\n",
    "#      - on peut aussi voir les rappels de chaque classe c'est a dire quel proportion de résultats positif réels a été identifié correctement.\n",
    "#      \n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred_rfc))\n",
    "# # analyse de la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test,pred_rfc ))\n",
    "# la matrice de confusion permet d'analyser la qualité d'un système de classification, comme son nom l'indique elle determine le niveau de confusion entre classe\n",
    "# les lignes c'est l'entré et les colonnes c'est le résultat de la classification par exemple :\n",
    "# - (0,0) => trois 0 ont été classé comme des 0 (Vrai positif)\n",
    "# - (0,X) => il y a jamais eu de confusion de la classe 0 avec d'autres caractère (Vrai Négatif)\n",
    "# - (X,0) => il y a eu un 8 et un 6 , réels qui ont été confondu avec 0 (Faux positifs)\n",
    "# ainsi plus la matrice est proche d'une matrice diagonale plus le système de classification est bon.\n",
    "#  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Support Vector Machine\n",
    "# Définition : les machines à vecteurs de support  sont des techniques d'apprentissage supervisé utilisé pour résoudre des problèmes de classification et de regressions, ils ont été développés dans les années 90 à partir des reflexions de Vladimir Vapnik , ils ont été rapidement implémenté pour leur capacité à s'adapter avec des données de grandes dimensions et pour leur résultats fiables. il parait que les performances des SVM est d'ordre au moins égales a celui des réseaux de neurones, leurs principes est simble il se base sur une vaste marge pour classifier les différentes classes, ainsi il offre une soupplesse permettant de mieux classifier\n",
    "\n",
    "# ### Avantages\n",
    "# - ils sont utilsé dans la classification et la régression\n",
    "# - gére et maintient la précision pour les données manquants\n",
    "# - quand le nombre d'arbres est plus grand que le nombres de donnée  dans le dataSet il est garanti  qu'il n y aura pas de sur-apprentissage a cause du system de bagging et sous-espaces aléatoires \n",
    "# - gére des grand dataset avec de grandes dimension\n",
    "\n",
    "# ### Inconvénients\n",
    "# - malgré qu'ils sont utile pour la classification , ils le sont moins que pour la régression du faite qu'il nous donne pas des valeurs pour savoir a quel pourcentage un element est de classe A ou B , en effet il répond il est de classe A ou de classe B , mais on ne sais pas a quel point.\n",
    "# - on a pas de controle sur ce que fait le modèle\n",
    "\n",
    "# ### Application\n",
    "# - le secteur des banques , dans l'évaluation des risque\n",
    "# - les gains/pertes dans le domaine de la bourse\n",
    "# - ....\n",
    "\n",
    "# ### mots clés \n",
    "\n",
    "# - Bagging : est un meta algorithm d'ensemble , qui augmente la stabilité et réduit la variance, les données sont piochées aléatoirement et mis dans des sous ensemble, a chaque entrainement le modèle utilise un sous ensemble totalement différent pour éviter le sur-apprentissage \n",
    "\n",
    "# ## Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=svm.SVC()\n",
    "clf.fit(X_train,Y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test,pred_clf ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc=MLPClassifier(hidden_layer_sizes=(50,50,50,50),max_iter=50)\n",
    "mlpc.fit(X_train,Y_train)\n",
    "pred_mlpc=mlpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred_mlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test,pred_mlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sur la courbe de dessin d'un coeur\n",
    "Xnew = [[-0.212148,-0.267778,-0.29948,-0.318689,-0.298137,-0.391123,-0.39166,-0.332926,-0.196772,-0.226409,-0.195603,-0.202815,-0.197956,-0.208973,-0.104984,0.102056,0.0200263,-0.0977367,-0.170617,-0.201229,-0.185005,0.0131545,0.0665064,0.107744,0.0964449,0.118824,0.0557161,-0.156992,-0.196657,-0.36906,-0.436593,-0.455107,-0.44989,-0.452929,-0.28455,-0.350204,-0.201105,-0.00209173,-0.00731671,0.0740171,-0.143884,-0.125816]]\n",
    "predictionSVM = clf.predict(Xnew)\n",
    "predictionRandomForest = rfc.predict(Xnew)\n",
    "predictionNNetwork = mlpc.predict(Xnew)\n",
    "print(\"resultat des supports vector machine est {0}\".format( predictionSVM))\n",
    "print(\"resultat des random Forest est {0}\".format( predictionRandomForest))\n",
    "print(\"resultat des réseaux de neurone est {0}\".format( predictionNNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sur la courbe de dessin qui veut rien dire\n",
    "Xnimp = [[-0.0294851,-0.064682,-0.273215,-0.595678,-0.220103,0.378522,-0.400078,-0.35578,-0.040492,0.616864,0.616197,0.661188,0.449561,0.416236,0.58469,0.660481,0.200372,0.204854,0.182162,0.196112,0.183642,0.205821,0.276499,0.573018,0.368421,0.147905,-0.227499,-0.257756,-0.146887,-0.119801,-0.131482,-0.0680083,-0.232264,0.169472,-0.273578,-0.235035,-0.337031,-0.309138,-0.506114,-0.000494707,0.161768,0.108695]]\n",
    "predictionSVM = clf.predict(Xnimp)\n",
    "predictionRandomForest = rfc.predict(Xnimp)\n",
    "predictionNNetwork = mlpc.predict(Xnimp)\n",
    "print(\"resultat des supports vector machine est {0}\".format( predictionSVM))\n",
    "print(\"resultat des random Forest est {0}\".format( predictionRandomForest))\n",
    "print(\"resultat des réseaux de neurone est {0}\".format( predictionNNetwork))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda9817c35b701a46e8b00010aaa52fe8e5",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}